{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QM9 Pro.\n",
    "Not sure what Iâ€™m supposed to call this file.  \n",
    "Plan is to keep this repo much neater than before.  \n",
    "Getting to work now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.nn import Linear, Parameter\n",
    "from typing import Any\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.data import DataLoader\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msharshe\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114153f50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "torch.manual_seed(2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/GDL/lib/python3.11/site-packages/torch_geometric/data/dataset.py:242: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, pass `force_reload=True` explicitly to reload the dataset.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = QM9(root='QM9_normalized_distances/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_1 = {\n",
    "    \"base_learning_rate\": 1e-3,\n",
    "    \"architecture\": \"Sparse 2-layer MPNN\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"dataset\": \"QM9\",\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "\n",
    "config_2 = {\n",
    "    \"base_learning_rate\": 1e-3,\n",
    "    \"architecture\": \"Sparse 2-layer MPNN\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"COSINEANNEALINGLR\",\n",
    "    \"dataset\": \"QM9\",\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" to fill in tomorrow.\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super(GCNConv, self).__init__(aggr='add') # \"Add\" aggregation.\n",
    "        self.embed_dimension = 32 # hard-coded here\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "    def message(self, x_j, edge_index, size):\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"QM9-Pro\",\n",
    "    config = config_1\n",
    ")\n",
    "\n",
    "# train\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
